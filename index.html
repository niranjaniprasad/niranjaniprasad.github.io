---
layout: page
title: Niranjani Prasad
---

<img class="col one right" src="/img/prof_pic2.jpg">

 I'm a first year PhD student in Computer Science at Princeton University, advised by Professor <a href="http://beehive.cs.princeton.edu/" target="blank">Barbara Engelhardt</a>. 
<br/><br/>

In 2013, I graduated from the University of Cambridge in Information and Computer Engineering (BA, MEng). Following this, I spent two years working at a <a href="https://www.speechmatics.com/" target="blank">start-up</a>, on research and development of speech recognition software. 

<br/><br/>

My current research interests are primarily in machine learning methods motivated by clinical medicine, spanning reinforcement learning, time series modelling, natural language processing and knowledge representation. 

<div id="research"></div>
<br/>
<br/>
<hr/><hr/>
<br/>

 <h3>Projects</h3> 
<br>

{% for project in site.portfolio %}

{% if project.redirect %}
<div class="project">
    <div class="thumbnail">
        <a href="{{ project.redirect }}" target="_blank">
        {% if project.img %}
        <img class="thumbnail" src="{{ project.img }}"/>
        {% else %}
        <div class="thumbnail blankbox"></div>
        {% endif %}    
        <span>
            <p>{{ project.description }}</p>
        </span>
        </a>
    </div>
</div>
{% else %}

<div class="project ">
    <div class="thumbnail">
        {% if project.img %}
                <a href="{{ site.baseurl }}{{ project.url }}">
<img class="thumbnail" src="{{ project.img }}"/>
        {% else %}
        <div class="thumbnail blankbox"></div>
        {% endif %}    
        <span>
            <p>{{ project.description }}</p>
        </span>
        </a>
    </div>
</div>

{% endif %}

{% endfor %}

<br/>

<font color="white">.</font>

<br/>
<br/> 
<hr/>
<hr/>

<br/>

<h3>Publications </h3>

<br>

Williams W, <b> Prasad N</b>, Mrva D, Ash T, Robinson T, "<a href="http://arxiv.org/pdf/1502.00512.pdf" target="blank">Scaling Recurrent Neural Network Language Models</a>" <i>IEEE International Conference on Acoustics, Speech & Signal Processing (ICASSP 2015)  </i>

<br><br>

<i>Abstract:</i> This paper investigates the scaling properties of Recurrent Neural
Network Language Models (RNNLMs). We discuss how
to train very large RNNs on GPUs and address the questions
of how RNNLMs scale with respect to model size, training-set
size, computational costs and memory. Our analysis shows that
despite being more costly to train, RNNLMs obtain much lower
perplexities on standard benchmarks than n-gram models. We
train the largest known RNNs and present relative word error
rates gains of 18% on an ASR task. We also present the new
lowest perplexities on the recently released billion word language
modelling benchmark, 1 BLEU point gain on machine
translation and a 17% relative hit rate gain in word prediction.

<!-- <br/><br/><i>(Presented at UKSpeech 2015)</i><br><br/> -->
<div id="cv"> </div>

<br/><br/>
<hr/><hr/>
<br/>
<h3> Curriculum Vitae </h3> 
<br/>
Attached here is my CV.

<div id="contact"> </div>
<br>
<br/> 
<hr/><hr/>
<br/>
<h3>  Contact </h3>

<br/>
To get in touch, email me at <b> np6 [at] princeton [dot] edu</b>. You can also find me on:

<span class="contacticon center">
  <a href="mailto:prasad.niranjani@gmail.com"><i class="fa fa-envelope-square"></i></a>
  <a href="https://github.com/niranjaniprasad" target="_blank"><i class="fa fa-github-square"></i></a>
  <a href="https://uk.linkedin.com/in/niranjani-prasad-a8891a34" target="_blank"><i class="fa fa-linkedin-square"></i></a>
  <!--<a href="http://tumblr.com" target="_blank"><i class="fa fa-tumblr-square"></i></a>
  <a href="https://twitter.com" target="_blank"><i class="fa fa-twitter-square"></i></a> -->
</span>
