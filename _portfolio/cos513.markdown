---
layout: post
title: Sparse, Low-dimensional & Multimodal Representations of Time Series for Mind-Reading
description: Sparse, Low-dimensional and Multimodal Representations of Time Series for Mind-Reading
img: /img/img20.jpg
---
<link href="https://fonts.googleapis.com/css?family=Alegreya+Sans" rel="stylesheet">

*This is joint work with [Kiran Vodrahalli](https://kiranvodrahalli.github.io/) and [Lydia Liu](http://lydiatliu.github.io/), under the guidance of Barbara Engelhardt.*

We introduce a new lens through which to analyse time-series brain data, with emphasis on sparse, low-dimensional joint representations of MEG and EEG data. Our main contribution is empirical validation suggesting that multimodal sparse CCA is able to achieve a low-dimensional representation of time series brain data which retains predictive and generative power. 

We also validate our methods using EEG representations of fMRI data: by using spatial information encoded by paired EEG-fMRI data with sparse CCA, we verify that these joint representations have predictive power by training SVMs to distinguish states of attention from base states.

Check out our project page [here](https://kiranvodrahalli.github.io/projects/cos513/) for more information.
<div>
	<img class="col three" src="{{ site.baseurl }}/img/513brains.png" alt="" title="fMRI Activations"/>
</div>
